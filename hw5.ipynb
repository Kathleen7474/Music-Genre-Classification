{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import re\n",
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import random\n",
    "# class裡面的括號表示繼承torch dataset的東西\n",
    "class MusicDataset(Dataset):\n",
    "    def __init__(self, audio_files, labels, sample_rate=22050, n_fft=2048, hop_length=512):\n",
    "        self.audio_files = audio_files\n",
    "        self.labels = labels\n",
    "        self.sample_rate = sample_rate\n",
    "        self.n_fft = n_fft\n",
    "        self.hop_length = hop_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.audio_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        length = 130\n",
    "        audio_file = self.audio_files[idx]\n",
    "        label = self.labels[idx]\n",
    "        audio, _ = librosa.load(audio_file, sr=self.sample_rate)\n",
    "        \n",
    "        # 新加入\n",
    "        return_data = []\n",
    "        n_segments = 10\n",
    "        n_mfcc = 40\n",
    "        samples_per_segment = int (self.sample_rate*30/n_segments)\n",
    "        \n",
    "        for n in range (n_segments):\n",
    "            mfcc = librosa.feature.mfcc(y=audio[samples_per_segment*n:samples_per_segment*(n+1)], sr=self.sample_rate, n_mfcc=n_mfcc, n_fft=self.n_fft, hop_length=self.hop_length)\n",
    "            # mfcc = librosa.feature.mfcc(audio[samples_per_segment*n:samples_per_segment*(n+1)],sr=self.sample_rate, n_mfcc=n_mfcc, n_fft=self.n_fft,hop_length=self.hop_length)\n",
    "            mfcc = mfcc.T\n",
    "            mfcc = torch.FloatTensor(mfcc)\n",
    "            # print(mfcc.shape)\n",
    "            if mfcc.shape[0] < length:\n",
    "                pad_width = length - mfcc.shape[0]\n",
    "                mfcc =  torch.from_numpy(np.pad(mfcc, ((0, pad_width), (0, 0)), 'constant'))\n",
    "            elif mfcc.shape[0] > length:\n",
    "                mfcc = mfcc[:, :length]\n",
    "            return_data.append(mfcc)\n",
    "            \n",
    "        # return_data = torch.cuda.FloatTensor(return_data)\n",
    "        label = torch.LongTensor([label])\n",
    "        cat_tensor = torch.cat(return_data , dim=0)\n",
    "        return cat_tensor, label\n",
    "    \n",
    "        # 原本的\n",
    "        # stft = librosa.stft(audio, n_fft=self.n_fft, hop_length=self.hop_length)\n",
    "        # magnitude, phase = librosa.magphase(stft)\n",
    "        # # print(stft.shape)\n",
    "        # magnitude = torch.FloatTensor(magnitude)\n",
    "        # phase = torch.FloatTensor(phase)\n",
    "        # if magnitude.shape[1] < length:\n",
    "        #     pad_width = length - magnitude.shape[1]\n",
    "        #     magnitude =  torch.from_numpy(np.pad(magnitude, ((0, 0), (0, pad_width)), 'constant'))\n",
    "        #     phase = torch.from_numpy(np.pad(phase, ((0, 0), (0, pad_width)), 'constant'))\n",
    "        # elif magnitude.shape[1] > length:\n",
    "        #     magnitude = magnitude[:, :length]\n",
    "        #     phase = phase[:, :length]\n",
    "        # label = torch.LongTensor([label])\n",
    "        # # print(\"call get item\",audio_file)\n",
    "        # # print(magnitude.shape)\n",
    "        # # print(phase.shape)\n",
    "        # return magnitude, phase, label\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_dir = Path('/home/fanal/disk2/luo/genre_classification/genre34/country')\n",
    "# file_list = os.listdir(data_dir)\n",
    "\n",
    "# index = 3\n",
    "# file_path = data_dir / file_list[index]\n",
    "# print(file_path)\n",
    "# print(file_list[index])\n",
    "# if (file_list[index]=='.DS_Store'):\n",
    "#     print(\"error\")\n",
    "# else:\n",
    "#     label = re.findall('^[a-z]+', file_path.name)[0]  # 提取標籤\n",
    "#     number = re.findall('\\d+', file_path.name)[0]  # 提取編號\n",
    "#     print(label)\n",
    "#     print(number)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class MusicCNN(nn.Module):\n",
    "    def __init__(self, n_classes):\n",
    "        super(MusicCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=0)\n",
    "        # self.conv1 = nn.Conv2d(in_channels=10, out_channels=32, kernel_size=3, padding=0)\n",
    "\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=128, kernel_size=3, padding=0)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.dropout1 = nn.Dropout(p=0.3)\n",
    "        self.conv3 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=0)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.maxpool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.dropout2 = nn.Dropout(p=0.3)\n",
    "        self.globalavgpool = nn.AdaptiveAvgPool2d(output_size=(1, 1))\n",
    "        self.fc1 = nn.Linear(in_features=128, out_features=512)\n",
    "        self.relu4 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(in_features=512, out_features=n_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.maxpool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.maxpool2(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.maxpool3(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.globalavgpool(x)\n",
    "        x = x.view(-1, 128)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu4(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "        \n",
    "# class MusicCNN(nn.Module):\n",
    "#     def __init__(self, n_classes):\n",
    "#         super(MusicCNN, self).__init__()\n",
    "#         self.conv1 = nn.Conv2d(10, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "#         # self.conv1 = nn.Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "#         self.bn1 = nn.BatchNorm2d(32)\n",
    "#         self.relu1 = nn.ReLU()\n",
    "#         self.maxpool1 = nn.MaxPool2d(kernel_size=(2, 2))\n",
    "#         self.conv2 = nn.Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "#         self.bn2 = nn.BatchNorm2d(64)\n",
    "#         self.relu2 = nn.ReLU()\n",
    "#         self.maxpool2 = nn.MaxPool2d(kernel_size=(2, 2))\n",
    "#         self.fc1 = nn.Linear(64 * 32 * 10, 128)\n",
    "#         # self.fc1 = nn.Linear(64 * 256 * 323, 128)\n",
    "\n",
    "#         self.relu3 = nn.ReLU()\n",
    "#         self.fc2 = nn.Linear(128, n_classes)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = x.view(x.size(0), -1, x.size(2), x.size(3)) # [batch_size, 10, height, width] -> [batch_size, 10*1, height, width]\n",
    "#         # x = x.unsqueeze(1)\n",
    "#         x = self.conv1(x)\n",
    "#         x = self.bn1(x)\n",
    "#         x = self.relu1(x)\n",
    "#         x = self.maxpool1(x)\n",
    "#         x = self.conv2(x)\n",
    "#         x = self.bn2(x)\n",
    "#         x = self.relu2(x)\n",
    "#         x = self.maxpool2(x)\n",
    "#         # print(\"before view\",x.shape)\n",
    "#         x = x.view(x.size(0), -1)\n",
    "#         x = self.fc1(x)\n",
    "#         x = self.relu3(x)\n",
    "#         x = self.fc2(x)\n",
    "#         return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_files = []\n",
    "labels = []\n",
    "postfix = ['12','34','56','78','910']\n",
    "for i in range(5):\n",
    "    music_folder = '/home/fanal/disk2/luo/genre_classification/genre'\n",
    "    music_folder += postfix[i]\n",
    "    genres = os.listdir(music_folder)        \n",
    "    for genre in genres:\n",
    "        if(genre !='.DS_Store'):\n",
    "            genre_folder = os.path.join(music_folder, genre)\n",
    "            genre_files = os.listdir(genre_folder)\n",
    "            for file in genre_files:\n",
    "                if file.endswith('.wav'):\n",
    "                    file_path = os.path.join(genre_folder, file)\n",
    "                    label = re.findall('^[a-z]+', file)[0]\n",
    "                    if (label==\"blues\"):\n",
    "                        label = 0\n",
    "                    elif (label==\"classical\"):\n",
    "                        label = 1\n",
    "                    elif (label==\"country\"):\n",
    "                        label = 2    \n",
    "                    elif (label==\"disco\"):\n",
    "                        label = 3\n",
    "                    elif (label==\"hiphop\"):\n",
    "                        label = 4 \n",
    "                    elif (label==\"jazz\"):\n",
    "                        label = 5 \n",
    "                    elif (label==\"metal\"):\n",
    "                        label = 6 \n",
    "                    elif (label==\"pop\"):\n",
    "                        label = 7\n",
    "                    elif (label==\"reggae\"):\n",
    "                        label = 8 \n",
    "                    elif (label==\"rock\"):\n",
    "                        label = 9  \n",
    "                    audio_files.append(file_path)\n",
    "                    labels.append(label)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "dataset = MusicDataset(audio_files, labels)\n",
    "\n",
    "# 沒有cross\n",
    "# train_size = int(len(dataset) * 0.8)\n",
    "# train_set, test_set = torch.utils.data.random_split(dataset, [train_size, len(dataset) - train_size])\n",
    "# dataloader = DataLoader(train_set, batch_size=32, shuffle=True)\n",
    "\n",
    "# cross validation\n",
    "fold_sizes = [len(dataset)//5]*5\n",
    "dataset_splits = torch.utils.data.random_split(dataset, fold_sizes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "def evaluate(model, dataloader):\n",
    "    model.eval()\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    with torch.no_grad():\n",
    "        for data, labels in dataloader:\n",
    "            # data= torch.stack(data)\n",
    "            # data = data.permute(1, 0, 2, 3)\n",
    "            data = data.type(torch.cuda.FloatTensor)\n",
    "            data.to(device)\n",
    "            labels = labels.type(torch.cuda.LongTensor)\n",
    "            labels.to(device)\n",
    "\n",
    "            outputs = model(data)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            labels = labels.squeeze()\n",
    "            # print('pred',predicted.shape)\n",
    "            # print('label',labels.shape)\n",
    "            # print((predicted == labels).sum())\n",
    "            total_samples += labels.size(0)\n",
    "            total_correct += (predicted == labels).sum().item()\n",
    "    # print(total_samples)\n",
    "    accuracy = 100.0 * total_correct / total_samples\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### torch summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device cuda\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [32, 32, 1298, 38]             320\n",
      "              ReLU-2         [32, 32, 1298, 38]               0\n",
      "         MaxPool2d-3          [32, 32, 649, 19]               0\n",
      "            Conv2d-4         [32, 128, 647, 17]          36,992\n",
      "              ReLU-5         [32, 128, 647, 17]               0\n",
      "         MaxPool2d-6          [32, 128, 323, 8]               0\n",
      "           Dropout-7          [32, 128, 323, 8]               0\n",
      "            Conv2d-8          [32, 128, 321, 6]         147,584\n",
      "              ReLU-9          [32, 128, 321, 6]               0\n",
      "        MaxPool2d-10          [32, 128, 160, 3]               0\n",
      "          Dropout-11          [32, 128, 160, 3]               0\n",
      "AdaptiveAvgPool2d-12            [32, 128, 1, 1]               0\n",
      "           Linear-13                  [32, 512]          66,048\n",
      "             ReLU-14                  [32, 512]               0\n",
      "           Linear-15                   [32, 10]           5,130\n",
      "================================================================\n",
      "Total params: 256,074\n",
      "Trainable params: 256,074\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 6.35\n",
      "Forward/backward pass size (MB): 1866.62\n",
      "Params size (MB): 0.98\n",
      "Estimated Total Size (MB): 1873.94\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from torchsummary import summary\n",
    "n_classes = 10\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"device\",device)\n",
    "model = MusicCNN(n_classes)\n",
    "model.to(device)\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "# summary(model, input_size=(1025,1293), batch_size=32)\n",
    "summary(model, input_size=(1300,40), batch_size=32)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Batch 0: Loss = 2.9075701236724854\n",
      "Epoch 0 Batch 10: Loss = 2.227437973022461\n",
      "Epoch 1 Batch 0: Loss = 2.138370990753174\n",
      "Epoch 1 Batch 10: Loss = 1.748353362083435\n",
      "Epoch 2 Batch 0: Loss = 1.8806076049804688\n",
      "Epoch 2 Batch 10: Loss = 1.5488409996032715\n",
      "Epoch 3 Batch 0: Loss = 1.3475744724273682\n",
      "Epoch 3 Batch 10: Loss = 1.3900036811828613\n",
      "Epoch 4 Batch 0: Loss = 1.204941987991333\n",
      "Epoch 4 Batch 10: Loss = 1.1224218606948853\n",
      "Epoch 5 Batch 0: Loss = 1.029836893081665\n",
      "Epoch 5 Batch 10: Loss = 1.2332992553710938\n",
      "Epoch 6 Batch 0: Loss = 1.3724204301834106\n",
      "Epoch 6 Batch 10: Loss = 1.2578963041305542\n",
      "Epoch 7 Batch 0: Loss = 1.0088543891906738\n",
      "Epoch 7 Batch 10: Loss = 1.0038859844207764\n",
      "Epoch 8 Batch 0: Loss = 0.9929409027099609\n",
      "Epoch 8 Batch 10: Loss = 0.8980150818824768\n",
      "Epoch 9 Batch 0: Loss = 0.9893862009048462\n",
      "Epoch 9 Batch 10: Loss = 1.2443101406097412\n",
      "Epoch 10 Batch 0: Loss = 0.964398205280304\n",
      "Epoch 10 Batch 10: Loss = 0.8416042327880859\n",
      "Epoch 11 Batch 0: Loss = 1.0424917936325073\n",
      "Epoch 11 Batch 10: Loss = 0.8947622179985046\n",
      "Epoch 12 Batch 0: Loss = 0.6827381253242493\n",
      "Epoch 12 Batch 10: Loss = 0.969098687171936\n",
      "Epoch 13 Batch 0: Loss = 1.3608543872833252\n",
      "Epoch 13 Batch 10: Loss = 0.8539088368415833\n",
      "Epoch 14 Batch 0: Loss = 1.0328354835510254\n",
      "Epoch 14 Batch 10: Loss = 0.8311119079589844\n",
      "Epoch 15 Batch 0: Loss = 0.8961925506591797\n",
      "Epoch 15 Batch 10: Loss = 0.6467239856719971\n",
      "Epoch 16 Batch 0: Loss = 0.972168505191803\n",
      "Epoch 16 Batch 10: Loss = 0.6205784678459167\n",
      "Epoch 17 Batch 0: Loss = 0.7649705410003662\n",
      "Epoch 17 Batch 10: Loss = 0.7070432305335999\n",
      "Epoch 18 Batch 0: Loss = 0.7887344360351562\n",
      "Epoch 18 Batch 10: Loss = 1.0653119087219238\n",
      "Epoch 19 Batch 0: Loss = 0.6845195889472961\n",
      "Epoch 19 Batch 10: Loss = 0.64138263463974\n",
      "Epoch 20 Batch 0: Loss = 0.5507871508598328\n",
      "Epoch 20 Batch 10: Loss = 0.6085696220397949\n",
      "Epoch 21 Batch 0: Loss = 0.9157745242118835\n",
      "Epoch 21 Batch 10: Loss = 0.6829262971878052\n",
      "Epoch 22 Batch 0: Loss = 0.4194427728652954\n",
      "Epoch 22 Batch 10: Loss = 0.5539344549179077\n",
      "Epoch 23 Batch 0: Loss = 0.7139244675636292\n",
      "Epoch 23 Batch 10: Loss = 0.6730028390884399\n",
      "Epoch 24 Batch 0: Loss = 0.4804987609386444\n",
      "Epoch 24 Batch 10: Loss = 0.42408522963523865\n",
      "Epoch 25 Batch 0: Loss = 0.41870802640914917\n",
      "Epoch 25 Batch 10: Loss = 0.7417673468589783\n",
      "Epoch 26 Batch 0: Loss = 0.49951818585395813\n",
      "Epoch 26 Batch 10: Loss = 0.6426142454147339\n",
      "Epoch 27 Batch 0: Loss = 0.4073644280433655\n",
      "Epoch 27 Batch 10: Loss = 0.45585694909095764\n",
      "Epoch 28 Batch 0: Loss = 0.7655874490737915\n",
      "Epoch 28 Batch 10: Loss = 0.5005106925964355\n",
      "Epoch 29 Batch 0: Loss = 0.4296000599861145\n",
      "Epoch 29 Batch 10: Loss = 0.5249091982841492\n",
      "Epoch 30 Batch 0: Loss = 0.49264466762542725\n",
      "Epoch 30 Batch 10: Loss = 0.4672406017780304\n",
      "Epoch 31 Batch 0: Loss = 0.2836250066757202\n",
      "Epoch 31 Batch 10: Loss = 0.36749687790870667\n",
      "Epoch 32 Batch 0: Loss = 0.6903559565544128\n",
      "Epoch 32 Batch 10: Loss = 0.3712899088859558\n",
      "Epoch 33 Batch 0: Loss = 0.2061927616596222\n",
      "Epoch 33 Batch 10: Loss = 0.458717942237854\n",
      "Epoch 34 Batch 0: Loss = 0.46736466884613037\n",
      "Epoch 34 Batch 10: Loss = 0.5955849885940552\n",
      "Epoch 35 Batch 0: Loss = 0.38463619351387024\n",
      "Epoch 35 Batch 10: Loss = 0.31563377380371094\n",
      "Epoch 36 Batch 0: Loss = 0.2795204520225525\n",
      "Epoch 36 Batch 10: Loss = 0.34548354148864746\n",
      "Epoch 37 Batch 0: Loss = 0.34746429324150085\n",
      "Epoch 37 Batch 10: Loss = 0.2561526596546173\n",
      "Epoch 38 Batch 0: Loss = 0.2964988946914673\n",
      "Epoch 38 Batch 10: Loss = 0.3845788240432739\n",
      "Epoch 39 Batch 0: Loss = 0.11128590255975723\n",
      "Epoch 39 Batch 10: Loss = 0.27886614203453064\n",
      "Epoch 40 Batch 0: Loss = 0.3493148982524872\n",
      "Epoch 40 Batch 10: Loss = 0.2669743001461029\n",
      "Epoch 41 Batch 0: Loss = 0.30650079250335693\n",
      "Epoch 41 Batch 10: Loss = 0.22985920310020447\n",
      "Epoch 42 Batch 0: Loss = 0.4944600760936737\n",
      "Epoch 42 Batch 10: Loss = 0.2824326157569885\n",
      "Epoch 43 Batch 0: Loss = 0.0988193079829216\n",
      "Epoch 43 Batch 10: Loss = 0.1450394243001938\n",
      "Epoch 44 Batch 0: Loss = 0.1930028647184372\n",
      "Epoch 44 Batch 10: Loss = 0.15971919894218445\n",
      "Epoch 45 Batch 0: Loss = 0.2916306257247925\n",
      "Epoch 45 Batch 10: Loss = 0.16356243193149567\n",
      "Epoch 46 Batch 0: Loss = 0.15652766823768616\n",
      "Epoch 46 Batch 10: Loss = 0.10378441959619522\n",
      "Epoch 47 Batch 0: Loss = 0.09521150588989258\n",
      "Epoch 47 Batch 10: Loss = 0.13017287850379944\n",
      "Epoch 48 Batch 0: Loss = 0.10208117216825485\n",
      "Epoch 48 Batch 10: Loss = 0.2296862155199051\n",
      "Epoch 49 Batch 0: Loss = 0.29207417368888855\n",
      "Epoch 49 Batch 10: Loss = 0.11274945735931396\n",
      "Epoch 50 Batch 0: Loss = 0.038978252559900284\n",
      "Epoch 50 Batch 10: Loss = 0.12349729984998703\n",
      "Epoch 51 Batch 0: Loss = 0.28048479557037354\n",
      "Epoch 51 Batch 10: Loss = 0.19091270864009857\n",
      "Epoch 52 Batch 0: Loss = 0.38253727555274963\n",
      "Epoch 52 Batch 10: Loss = 0.15132175385951996\n",
      "Epoch 53 Batch 0: Loss = 0.09003828465938568\n",
      "Epoch 53 Batch 10: Loss = 0.11149577051401138\n",
      "Epoch 54 Batch 0: Loss = 0.03310330957174301\n",
      "Epoch 54 Batch 10: Loss = 0.17038381099700928\n",
      "Epoch 55 Batch 0: Loss = 0.1264508068561554\n",
      "Epoch 55 Batch 10: Loss = 0.12683027982711792\n",
      "Epoch 56 Batch 0: Loss = 0.06696590036153793\n",
      "Epoch 56 Batch 10: Loss = 0.05081639811396599\n",
      "Epoch 57 Batch 0: Loss = 0.07140649110078812\n",
      "Epoch 57 Batch 10: Loss = 0.029014961794018745\n",
      "Epoch 58 Batch 0: Loss = 0.062273718416690826\n",
      "Epoch 58 Batch 10: Loss = 0.08626068383455276\n",
      "Epoch 59 Batch 0: Loss = 0.04893934354186058\n",
      "Epoch 59 Batch 10: Loss = 0.11998610943555832\n",
      "Epoch 60 Batch 0: Loss = 0.08334439247846603\n",
      "Epoch 60 Batch 10: Loss = 0.21253164112567902\n",
      "Epoch 61 Batch 0: Loss = 0.04096603766083717\n",
      "Epoch 61 Batch 10: Loss = 0.034464526921510696\n",
      "Epoch 62 Batch 0: Loss = 0.026300836354494095\n",
      "Epoch 62 Batch 10: Loss = 0.15003231167793274\n",
      "Epoch 63 Batch 0: Loss = 0.19372926652431488\n",
      "Epoch 63 Batch 10: Loss = 0.21275193989276886\n",
      "Epoch 64 Batch 0: Loss = 0.06072769686579704\n",
      "Epoch 64 Batch 10: Loss = 0.31243300437927246\n",
      "Epoch 65 Batch 0: Loss = 0.3210773766040802\n",
      "Epoch 65 Batch 10: Loss = 0.2005365639925003\n",
      "Epoch 66 Batch 0: Loss = 0.07870295643806458\n",
      "Epoch 66 Batch 10: Loss = 0.07031671702861786\n",
      "Epoch 67 Batch 0: Loss = 0.043624747544527054\n",
      "Epoch 67 Batch 10: Loss = 0.028471659868955612\n",
      "Epoch 68 Batch 0: Loss = 0.20764395594596863\n",
      "Epoch 68 Batch 10: Loss = 0.12145700305700302\n",
      "Epoch 69 Batch 0: Loss = 0.06024034693837166\n",
      "Epoch 69 Batch 10: Loss = 0.15293613076210022\n",
      "Epoch 70 Batch 0: Loss = 0.03294295445084572\n",
      "Epoch 70 Batch 10: Loss = 0.21731290221214294\n",
      "Epoch 71 Batch 0: Loss = 0.12447250634431839\n",
      "Epoch 71 Batch 10: Loss = 0.026441924273967743\n",
      "Epoch 72 Batch 0: Loss = 0.026160888373851776\n",
      "Epoch 72 Batch 10: Loss = 0.06704851239919662\n",
      "Epoch 73 Batch 0: Loss = 0.0270098689943552\n",
      "Epoch 73 Batch 10: Loss = 0.11624718457460403\n",
      "Epoch 74 Batch 0: Loss = 0.07256108522415161\n",
      "Epoch 74 Batch 10: Loss = 0.05858843773603439\n",
      "Epoch 75 Batch 0: Loss = 0.07040050625801086\n",
      "Epoch 75 Batch 10: Loss = 0.04881276190280914\n",
      "Epoch 76 Batch 0: Loss = 0.3354276716709137\n",
      "Epoch 76 Batch 10: Loss = 0.3866358995437622\n",
      "Epoch 77 Batch 0: Loss = 0.11031613498926163\n",
      "Epoch 77 Batch 10: Loss = 0.10674107074737549\n",
      "Epoch 78 Batch 0: Loss = 0.09271760284900665\n",
      "Epoch 78 Batch 10: Loss = 0.09450125694274902\n",
      "Epoch 79 Batch 0: Loss = 0.133899986743927\n",
      "Epoch 79 Batch 10: Loss = 0.03140709921717644\n",
      "Epoch 80 Batch 0: Loss = 0.10967648774385452\n",
      "Epoch 80 Batch 10: Loss = 0.022463636472821236\n",
      "Epoch 81 Batch 0: Loss = 0.03642050549387932\n",
      "Epoch 81 Batch 10: Loss = 0.029572222381830215\n",
      "Epoch 82 Batch 0: Loss = 0.0063943639397621155\n",
      "Epoch 82 Batch 10: Loss = 0.018733011558651924\n",
      "Epoch 83 Batch 0: Loss = 0.007485683541744947\n",
      "Epoch 83 Batch 10: Loss = 0.009608296677470207\n",
      "Epoch 84 Batch 0: Loss = 0.01010386273264885\n",
      "Epoch 84 Batch 10: Loss = 0.015329304151237011\n",
      "Epoch 85 Batch 0: Loss = 0.011994030326604843\n",
      "Epoch 85 Batch 10: Loss = 0.004232428967952728\n",
      "Epoch 86 Batch 0: Loss = 0.0066369823180139065\n",
      "Epoch 86 Batch 10: Loss = 0.009367340244352818\n",
      "Epoch 87 Batch 0: Loss = 0.004157018382102251\n",
      "Epoch 87 Batch 10: Loss = 0.007121776696294546\n",
      "Epoch 88 Batch 0: Loss = 0.004035484045743942\n",
      "Epoch 88 Batch 10: Loss = 0.0047245933674275875\n",
      "Epoch 89 Batch 0: Loss = 0.004355176817625761\n",
      "Epoch 89 Batch 10: Loss = 0.004508604761213064\n",
      "Epoch 90 Batch 0: Loss = 0.0016550248255953193\n",
      "Epoch 90 Batch 10: Loss = 0.005299106240272522\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91 Batch 0: Loss = 0.010563721880316734\n",
      "Epoch 91 Batch 10: Loss = 0.002294724341481924\n",
      "Epoch 92 Batch 0: Loss = 0.0028725003357976675\n",
      "Epoch 92 Batch 10: Loss = 0.003230625530704856\n",
      "Epoch 93 Batch 0: Loss = 0.003975998144596815\n",
      "Epoch 93 Batch 10: Loss = 0.005756074097007513\n",
      "Epoch 94 Batch 0: Loss = 0.0034853892866522074\n",
      "Epoch 94 Batch 10: Loss = 0.004953098017722368\n",
      "Epoch 95 Batch 0: Loss = 0.0046235849149525166\n",
      "Epoch 95 Batch 10: Loss = 0.0018712474266067147\n",
      "Epoch 96 Batch 0: Loss = 0.00278697581961751\n",
      "Epoch 96 Batch 10: Loss = 0.003389835124835372\n",
      "Epoch 97 Batch 0: Loss = 0.0024576536379754543\n",
      "Epoch 97 Batch 10: Loss = 0.0020840021315962076\n",
      "Epoch 98 Batch 0: Loss = 0.0011818730272352695\n",
      "Epoch 98 Batch 10: Loss = 0.005840074270963669\n",
      "Epoch 99 Batch 0: Loss = 0.00195406679995358\n",
      "Epoch 99 Batch 10: Loss = 0.0027874140068888664\n",
      "Test accuracy: 77.00%\n",
      "Epoch 0 Batch 0: Loss = 2.7189083099365234\n",
      "Epoch 0 Batch 10: Loss = 2.1872684955596924\n",
      "Epoch 1 Batch 0: Loss = 2.1185836791992188\n",
      "Epoch 1 Batch 10: Loss = 1.678444266319275\n",
      "Epoch 2 Batch 0: Loss = 1.599786400794983\n",
      "Epoch 2 Batch 10: Loss = 1.7667145729064941\n",
      "Epoch 3 Batch 0: Loss = 1.5183250904083252\n",
      "Epoch 3 Batch 10: Loss = 1.4023643732070923\n",
      "Epoch 4 Batch 0: Loss = 1.3739126920700073\n",
      "Epoch 4 Batch 10: Loss = 1.3125492334365845\n",
      "Epoch 5 Batch 0: Loss = 1.5762063264846802\n",
      "Epoch 5 Batch 10: Loss = 1.2349961996078491\n",
      "Epoch 6 Batch 0: Loss = 1.198652744293213\n",
      "Epoch 6 Batch 10: Loss = 1.435996651649475\n",
      "Epoch 7 Batch 0: Loss = 1.0082299709320068\n",
      "Epoch 7 Batch 10: Loss = 1.2007756233215332\n",
      "Epoch 8 Batch 0: Loss = 1.233351230621338\n",
      "Epoch 8 Batch 10: Loss = 1.0552138090133667\n",
      "Epoch 9 Batch 0: Loss = 0.9680332541465759\n",
      "Epoch 9 Batch 10: Loss = 1.1166502237319946\n",
      "Epoch 10 Batch 0: Loss = 0.7323485612869263\n",
      "Epoch 10 Batch 10: Loss = 0.9249639511108398\n",
      "Epoch 11 Batch 0: Loss = 0.7957742214202881\n",
      "Epoch 11 Batch 10: Loss = 1.1794582605361938\n",
      "Epoch 12 Batch 0: Loss = 0.9799053072929382\n",
      "Epoch 12 Batch 10: Loss = 0.7361329793930054\n",
      "Epoch 13 Batch 0: Loss = 0.6941043138504028\n",
      "Epoch 13 Batch 10: Loss = 0.5354687571525574\n",
      "Epoch 14 Batch 0: Loss = 0.915523111820221\n",
      "Epoch 14 Batch 10: Loss = 0.8375536799430847\n",
      "Epoch 15 Batch 0: Loss = 0.5646367073059082\n",
      "Epoch 15 Batch 10: Loss = 0.6130534410476685\n",
      "Epoch 16 Batch 0: Loss = 0.9756760597229004\n",
      "Epoch 16 Batch 10: Loss = 0.6335212588310242\n",
      "Epoch 17 Batch 0: Loss = 0.6488518118858337\n",
      "Epoch 17 Batch 10: Loss = 1.0662108659744263\n",
      "Epoch 18 Batch 0: Loss = 0.7866095900535583\n",
      "Epoch 18 Batch 10: Loss = 0.7421640157699585\n",
      "Epoch 19 Batch 0: Loss = 1.2913025617599487\n",
      "Epoch 19 Batch 10: Loss = 0.7162975668907166\n",
      "Epoch 20 Batch 0: Loss = 0.48841455578804016\n",
      "Epoch 20 Batch 10: Loss = 0.6846813559532166\n",
      "Epoch 21 Batch 0: Loss = 0.6080988645553589\n",
      "Epoch 21 Batch 10: Loss = 0.4263305962085724\n",
      "Epoch 22 Batch 0: Loss = 0.5803717374801636\n",
      "Epoch 22 Batch 10: Loss = 0.6724040508270264\n",
      "Epoch 23 Batch 0: Loss = 0.5243368744850159\n",
      "Epoch 23 Batch 10: Loss = 0.5148304104804993\n",
      "Epoch 24 Batch 0: Loss = 0.6655265092849731\n",
      "Epoch 24 Batch 10: Loss = 0.34764668345451355\n",
      "Epoch 25 Batch 0: Loss = 0.540734589099884\n",
      "Epoch 25 Batch 10: Loss = 0.43666231632232666\n",
      "Epoch 26 Batch 0: Loss = 0.5142027735710144\n",
      "Epoch 26 Batch 10: Loss = 0.6121353507041931\n",
      "Epoch 27 Batch 0: Loss = 0.3368396759033203\n",
      "Epoch 27 Batch 10: Loss = 0.5035987496376038\n",
      "Epoch 28 Batch 0: Loss = 0.5783045887947083\n",
      "Epoch 28 Batch 10: Loss = 0.36177968978881836\n",
      "Epoch 29 Batch 0: Loss = 0.3157685697078705\n",
      "Epoch 29 Batch 10: Loss = 0.38292253017425537\n",
      "Epoch 30 Batch 0: Loss = 0.5771321058273315\n",
      "Epoch 30 Batch 10: Loss = 0.5707401633262634\n",
      "Epoch 31 Batch 0: Loss = 0.3850194215774536\n",
      "Epoch 31 Batch 10: Loss = 0.3891189396381378\n",
      "Epoch 32 Batch 0: Loss = 0.2908862233161926\n",
      "Epoch 32 Batch 10: Loss = 0.3971380293369293\n",
      "Epoch 33 Batch 0: Loss = 0.3076775372028351\n",
      "Epoch 33 Batch 10: Loss = 0.23190215229988098\n",
      "Epoch 34 Batch 0: Loss = 0.1580733060836792\n",
      "Epoch 34 Batch 10: Loss = 0.5453552007675171\n",
      "Epoch 35 Batch 0: Loss = 0.3279525339603424\n",
      "Epoch 35 Batch 10: Loss = 0.29065951704978943\n",
      "Epoch 36 Batch 0: Loss = 0.7172966003417969\n",
      "Epoch 36 Batch 10: Loss = 0.5575326681137085\n",
      "Epoch 37 Batch 0: Loss = 0.25723105669021606\n",
      "Epoch 37 Batch 10: Loss = 0.32272523641586304\n",
      "Epoch 38 Batch 0: Loss = 0.4005332291126251\n",
      "Epoch 38 Batch 10: Loss = 0.5104917883872986\n",
      "Epoch 39 Batch 0: Loss = 0.2136303037405014\n",
      "Epoch 39 Batch 10: Loss = 0.32024896144866943\n",
      "Epoch 40 Batch 0: Loss = 0.45461100339889526\n",
      "Epoch 40 Batch 10: Loss = 0.28456616401672363\n",
      "Epoch 41 Batch 0: Loss = 0.17308776080608368\n",
      "Epoch 41 Batch 10: Loss = 0.26655706763267517\n",
      "Epoch 42 Batch 0: Loss = 0.20156577229499817\n",
      "Epoch 42 Batch 10: Loss = 0.09647753089666367\n",
      "Epoch 43 Batch 0: Loss = 0.17835119366645813\n",
      "Epoch 43 Batch 10: Loss = 0.38598310947418213\n",
      "Epoch 44 Batch 0: Loss = 0.20494389533996582\n",
      "Epoch 44 Batch 10: Loss = 1.2061405181884766\n",
      "Epoch 45 Batch 0: Loss = 0.28587090969085693\n",
      "Epoch 45 Batch 10: Loss = 0.4398210048675537\n",
      "Epoch 46 Batch 0: Loss = 0.24050256609916687\n",
      "Epoch 46 Batch 10: Loss = 0.3284969925880432\n",
      "Epoch 47 Batch 0: Loss = 0.4079491198062897\n",
      "Epoch 47 Batch 10: Loss = 0.21814367175102234\n",
      "Epoch 48 Batch 0: Loss = 0.17294752597808838\n",
      "Epoch 48 Batch 10: Loss = 0.32832685112953186\n",
      "Epoch 49 Batch 0: Loss = 0.20553849637508392\n",
      "Epoch 49 Batch 10: Loss = 0.07453879714012146\n",
      "Epoch 50 Batch 0: Loss = 0.3542993664741516\n",
      "Epoch 50 Batch 10: Loss = 0.18581151962280273\n",
      "Epoch 51 Batch 0: Loss = 0.27993249893188477\n",
      "Epoch 51 Batch 10: Loss = 0.1920253187417984\n",
      "Epoch 52 Batch 0: Loss = 0.22735334932804108\n",
      "Epoch 52 Batch 10: Loss = 0.5575864911079407\n",
      "Epoch 53 Batch 0: Loss = 0.13416266441345215\n",
      "Epoch 53 Batch 10: Loss = 0.13397854566574097\n",
      "Epoch 54 Batch 0: Loss = 0.1500774770975113\n",
      "Epoch 54 Batch 10: Loss = 0.1657905876636505\n",
      "Epoch 55 Batch 0: Loss = 0.11074495315551758\n",
      "Epoch 55 Batch 10: Loss = 0.14135141670703888\n",
      "Epoch 56 Batch 0: Loss = 0.11449172347784042\n",
      "Epoch 56 Batch 10: Loss = 0.15178850293159485\n",
      "Epoch 57 Batch 0: Loss = 0.28639543056488037\n",
      "Epoch 57 Batch 10: Loss = 0.30003243684768677\n",
      "Epoch 58 Batch 0: Loss = 0.06831757724285126\n",
      "Epoch 58 Batch 10: Loss = 0.1608189344406128\n",
      "Epoch 59 Batch 0: Loss = 0.13927386701107025\n",
      "Epoch 59 Batch 10: Loss = 0.18356953561306\n",
      "Epoch 60 Batch 0: Loss = 0.10787016153335571\n",
      "Epoch 60 Batch 10: Loss = 0.10300204902887344\n",
      "Epoch 61 Batch 0: Loss = 0.09488595277070999\n",
      "Epoch 61 Batch 10: Loss = 0.18971501290798187\n",
      "Epoch 62 Batch 0: Loss = 0.09328674525022507\n",
      "Epoch 62 Batch 10: Loss = 0.03920217603445053\n",
      "Epoch 63 Batch 0: Loss = 0.17135080695152283\n",
      "Epoch 63 Batch 10: Loss = 0.11092042922973633\n",
      "Epoch 64 Batch 0: Loss = 0.15473568439483643\n",
      "Epoch 64 Batch 10: Loss = 0.06232442334294319\n",
      "Epoch 65 Batch 0: Loss = 0.11495474725961685\n",
      "Epoch 65 Batch 10: Loss = 0.152056023478508\n",
      "Epoch 66 Batch 0: Loss = 0.11959672719240189\n",
      "Epoch 66 Batch 10: Loss = 0.17707942426204681\n",
      "Epoch 67 Batch 0: Loss = 0.050785526633262634\n",
      "Epoch 67 Batch 10: Loss = 0.26808875799179077\n",
      "Epoch 68 Batch 0: Loss = 0.4831852316856384\n",
      "Epoch 68 Batch 10: Loss = 0.02072879672050476\n",
      "Epoch 69 Batch 0: Loss = 0.037254758179187775\n",
      "Epoch 69 Batch 10: Loss = 0.07269418239593506\n",
      "Epoch 70 Batch 0: Loss = 0.03739415481686592\n",
      "Epoch 70 Batch 10: Loss = 0.07466268539428711\n",
      "Epoch 71 Batch 0: Loss = 0.018193453550338745\n",
      "Epoch 71 Batch 10: Loss = 0.02495400235056877\n",
      "Epoch 72 Batch 0: Loss = 0.020613763481378555\n",
      "Epoch 72 Batch 10: Loss = 0.023244036361575127\n",
      "Epoch 73 Batch 0: Loss = 0.013785668648779392\n",
      "Epoch 73 Batch 10: Loss = 0.03420206904411316\n",
      "Epoch 74 Batch 0: Loss = 0.043111544102430344\n",
      "Epoch 74 Batch 10: Loss = 0.07162532210350037\n",
      "Epoch 75 Batch 0: Loss = 0.02891402691602707\n",
      "Epoch 75 Batch 10: Loss = 1.1411049365997314\n",
      "Epoch 76 Batch 0: Loss = 0.5634312033653259\n",
      "Epoch 76 Batch 10: Loss = 0.07509388029575348\n",
      "Epoch 77 Batch 0: Loss = 0.11048800498247147\n",
      "Epoch 77 Batch 10: Loss = 0.09050825238227844\n",
      "Epoch 78 Batch 0: Loss = 0.11684571206569672\n",
      "Epoch 78 Batch 10: Loss = 0.15912824869155884\n",
      "Epoch 79 Batch 0: Loss = 0.26458877325057983\n",
      "Epoch 79 Batch 10: Loss = 0.04850956052541733\n",
      "Epoch 80 Batch 0: Loss = 0.0549776628613472\n",
      "Epoch 80 Batch 10: Loss = 0.09665624797344208\n",
      "Epoch 81 Batch 0: Loss = 0.1190652996301651\n",
      "Epoch 81 Batch 10: Loss = 0.06214854493737221\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82 Batch 0: Loss = 0.022771138697862625\n",
      "Epoch 82 Batch 10: Loss = 0.04075034707784653\n",
      "Epoch 83 Batch 0: Loss = 0.04437469318509102\n",
      "Epoch 83 Batch 10: Loss = 0.03556814417243004\n",
      "Epoch 84 Batch 0: Loss = 0.015073629096150398\n",
      "Epoch 84 Batch 10: Loss = 0.006881672888994217\n",
      "Epoch 85 Batch 0: Loss = 0.00779313687235117\n",
      "Epoch 85 Batch 10: Loss = 0.007822347804903984\n",
      "Epoch 86 Batch 0: Loss = 0.01173210609704256\n",
      "Epoch 86 Batch 10: Loss = 0.008207172155380249\n",
      "Epoch 87 Batch 0: Loss = 0.0019578346982598305\n",
      "Epoch 87 Batch 10: Loss = 0.011884495615959167\n",
      "Epoch 88 Batch 0: Loss = 0.0036836520303040743\n",
      "Epoch 88 Batch 10: Loss = 0.005854309070855379\n",
      "Epoch 89 Batch 0: Loss = 0.0035491790622472763\n",
      "Epoch 89 Batch 10: Loss = 0.005509711802005768\n",
      "Epoch 90 Batch 0: Loss = 0.008466463536024094\n",
      "Epoch 90 Batch 10: Loss = 0.006174588110297918\n",
      "Epoch 91 Batch 0: Loss = 0.002106346655637026\n",
      "Epoch 91 Batch 10: Loss = 0.002433375921100378\n",
      "Epoch 92 Batch 0: Loss = 0.003614828223362565\n",
      "Epoch 92 Batch 10: Loss = 0.008638828992843628\n",
      "Epoch 93 Batch 0: Loss = 0.00501653365790844\n",
      "Epoch 93 Batch 10: Loss = 0.0062915245071053505\n",
      "Epoch 94 Batch 0: Loss = 0.004988519009202719\n",
      "Epoch 94 Batch 10: Loss = 0.003469859017059207\n",
      "Epoch 95 Batch 0: Loss = 0.005452045239508152\n",
      "Epoch 95 Batch 10: Loss = 0.004998078104108572\n",
      "Epoch 96 Batch 0: Loss = 0.002016443992033601\n",
      "Epoch 96 Batch 10: Loss = 0.0010266731260344386\n",
      "Epoch 97 Batch 0: Loss = 0.002215631539002061\n",
      "Epoch 97 Batch 10: Loss = 0.0010890238918364048\n",
      "Epoch 98 Batch 0: Loss = 0.0023239757865667343\n",
      "Epoch 98 Batch 10: Loss = 0.0015372985508292913\n",
      "Epoch 99 Batch 0: Loss = 0.0024431527126580477\n",
      "Epoch 99 Batch 10: Loss = 0.005738529842346907\n",
      "Test accuracy: 83.00%\n",
      "Epoch 0 Batch 0: Loss = 2.456768035888672\n",
      "Epoch 0 Batch 10: Loss = 2.185997247695923\n",
      "Epoch 1 Batch 0: Loss = 2.042772054672241\n",
      "Epoch 1 Batch 10: Loss = 1.6498651504516602\n",
      "Epoch 2 Batch 0: Loss = 1.5141997337341309\n",
      "Epoch 2 Batch 10: Loss = 1.124531865119934\n",
      "Epoch 3 Batch 0: Loss = 1.481236219406128\n",
      "Epoch 3 Batch 10: Loss = 1.3138335943222046\n",
      "Epoch 4 Batch 0: Loss = 1.417099952697754\n",
      "Epoch 4 Batch 10: Loss = 1.0954670906066895\n",
      "Epoch 5 Batch 0: Loss = 1.5121831893920898\n",
      "Epoch 5 Batch 10: Loss = 0.8843162059783936\n",
      "Epoch 6 Batch 0: Loss = 1.036539912223816\n",
      "Epoch 6 Batch 10: Loss = 1.1913479566574097\n",
      "Epoch 7 Batch 0: Loss = 1.593014121055603\n",
      "Epoch 7 Batch 10: Loss = 0.9720610976219177\n",
      "Epoch 8 Batch 0: Loss = 0.977535605430603\n",
      "Epoch 8 Batch 10: Loss = 0.9834885597229004\n",
      "Epoch 9 Batch 0: Loss = 0.7006742358207703\n",
      "Epoch 9 Batch 10: Loss = 0.6802404522895813\n",
      "Epoch 10 Batch 0: Loss = 0.8553227782249451\n",
      "Epoch 10 Batch 10: Loss = 1.2730789184570312\n",
      "Epoch 11 Batch 0: Loss = 0.9620679616928101\n",
      "Epoch 11 Batch 10: Loss = 0.7130136489868164\n",
      "Epoch 12 Batch 0: Loss = 0.6678696870803833\n",
      "Epoch 12 Batch 10: Loss = 0.972890317440033\n",
      "Epoch 13 Batch 0: Loss = 0.9802797436714172\n",
      "Epoch 13 Batch 10: Loss = 0.8176952600479126\n",
      "Epoch 14 Batch 0: Loss = 0.8671273589134216\n",
      "Epoch 14 Batch 10: Loss = 0.5103780031204224\n",
      "Epoch 15 Batch 0: Loss = 0.7046673893928528\n",
      "Epoch 15 Batch 10: Loss = 0.8680527806282043\n",
      "Epoch 16 Batch 0: Loss = 0.5513955950737\n",
      "Epoch 16 Batch 10: Loss = 0.7425673007965088\n",
      "Epoch 17 Batch 0: Loss = 0.6853549480438232\n",
      "Epoch 17 Batch 10: Loss = 0.863835334777832\n",
      "Epoch 18 Batch 0: Loss = 0.8188820481300354\n",
      "Epoch 18 Batch 10: Loss = 0.8933590650558472\n",
      "Epoch 19 Batch 0: Loss = 0.8490605354309082\n",
      "Epoch 19 Batch 10: Loss = 0.7912837266921997\n",
      "Epoch 20 Batch 0: Loss = 0.7120030522346497\n",
      "Epoch 20 Batch 10: Loss = 0.6021025776863098\n",
      "Epoch 21 Batch 0: Loss = 0.5127520561218262\n",
      "Epoch 21 Batch 10: Loss = 0.7797107100486755\n",
      "Epoch 22 Batch 0: Loss = 0.936667263507843\n",
      "Epoch 22 Batch 10: Loss = 0.44420719146728516\n",
      "Epoch 23 Batch 0: Loss = 0.507720947265625\n",
      "Epoch 23 Batch 10: Loss = 0.3962988257408142\n",
      "Epoch 24 Batch 0: Loss = 0.640806257724762\n",
      "Epoch 24 Batch 10: Loss = 0.4639924466609955\n",
      "Epoch 25 Batch 0: Loss = 0.45910513401031494\n",
      "Epoch 25 Batch 10: Loss = 0.5367668271064758\n",
      "Epoch 26 Batch 0: Loss = 0.5787285566329956\n",
      "Epoch 26 Batch 10: Loss = 0.5758684873580933\n",
      "Epoch 27 Batch 0: Loss = 0.3601253628730774\n",
      "Epoch 27 Batch 10: Loss = 0.5119662284851074\n",
      "Epoch 28 Batch 0: Loss = 0.8053461313247681\n",
      "Epoch 28 Batch 10: Loss = 0.3379382789134979\n",
      "Epoch 29 Batch 0: Loss = 0.37444809079170227\n",
      "Epoch 29 Batch 10: Loss = 0.2587543725967407\n",
      "Epoch 30 Batch 0: Loss = 0.5401085615158081\n",
      "Epoch 30 Batch 10: Loss = 0.4925802946090698\n",
      "Epoch 31 Batch 0: Loss = 0.38453516364097595\n",
      "Epoch 31 Batch 10: Loss = 0.6982091069221497\n",
      "Epoch 32 Batch 0: Loss = 0.527473509311676\n",
      "Epoch 32 Batch 10: Loss = 0.27241218090057373\n",
      "Epoch 33 Batch 0: Loss = 0.32349348068237305\n",
      "Epoch 33 Batch 10: Loss = 0.4869470000267029\n",
      "Epoch 34 Batch 0: Loss = 0.14187437295913696\n",
      "Epoch 34 Batch 10: Loss = 0.43098530173301697\n",
      "Epoch 35 Batch 0: Loss = 0.4087288975715637\n",
      "Epoch 35 Batch 10: Loss = 0.20487235486507416\n",
      "Epoch 36 Batch 0: Loss = 0.3037044405937195\n",
      "Epoch 36 Batch 10: Loss = 0.19065554440021515\n",
      "Epoch 37 Batch 0: Loss = 0.36648258566856384\n",
      "Epoch 37 Batch 10: Loss = 0.2795058488845825\n",
      "Epoch 38 Batch 0: Loss = 0.3517071604728699\n",
      "Epoch 38 Batch 10: Loss = 0.45475858449935913\n",
      "Epoch 39 Batch 0: Loss = 0.32641178369522095\n",
      "Epoch 39 Batch 10: Loss = 0.3956751823425293\n",
      "Epoch 40 Batch 0: Loss = 0.1575905978679657\n",
      "Epoch 40 Batch 10: Loss = 0.696729838848114\n",
      "Epoch 41 Batch 0: Loss = 0.3353053629398346\n",
      "Epoch 41 Batch 10: Loss = 0.2732127010822296\n",
      "Epoch 42 Batch 0: Loss = 0.3142995536327362\n",
      "Epoch 42 Batch 10: Loss = 0.10957108438014984\n",
      "Epoch 43 Batch 0: Loss = 0.15671205520629883\n",
      "Epoch 43 Batch 10: Loss = 0.14374230802059174\n",
      "Epoch 44 Batch 0: Loss = 0.2176821082830429\n",
      "Epoch 44 Batch 10: Loss = 0.1943390816450119\n",
      "Epoch 45 Batch 0: Loss = 0.13742664456367493\n",
      "Epoch 45 Batch 10: Loss = 0.34792599081993103\n",
      "Epoch 46 Batch 0: Loss = 0.10321231186389923\n",
      "Epoch 46 Batch 10: Loss = 0.2755976915359497\n",
      "Epoch 47 Batch 0: Loss = 0.22522276639938354\n",
      "Epoch 47 Batch 10: Loss = 0.15046709775924683\n",
      "Epoch 48 Batch 0: Loss = 0.23905716836452484\n",
      "Epoch 48 Batch 10: Loss = 0.3608037531375885\n",
      "Epoch 49 Batch 0: Loss = 0.1401548683643341\n",
      "Epoch 49 Batch 10: Loss = 0.2943803071975708\n",
      "Epoch 50 Batch 0: Loss = 0.24981172382831573\n",
      "Epoch 50 Batch 10: Loss = 0.28425320982933044\n",
      "Epoch 51 Batch 0: Loss = 0.27396082878112793\n",
      "Epoch 51 Batch 10: Loss = 0.1947779357433319\n",
      "Epoch 52 Batch 0: Loss = 0.12068347632884979\n",
      "Epoch 52 Batch 10: Loss = 0.11464967578649521\n",
      "Epoch 53 Batch 0: Loss = 0.12546364963054657\n",
      "Epoch 53 Batch 10: Loss = 0.31547999382019043\n",
      "Epoch 54 Batch 0: Loss = 0.16187220811843872\n",
      "Epoch 54 Batch 10: Loss = 0.12302162498235703\n",
      "Epoch 55 Batch 0: Loss = 0.19467180967330933\n",
      "Epoch 55 Batch 10: Loss = 0.15032361447811127\n",
      "Epoch 56 Batch 0: Loss = 0.059982262551784515\n",
      "Epoch 56 Batch 10: Loss = 0.3537759780883789\n",
      "Epoch 57 Batch 0: Loss = 0.5664186477661133\n",
      "Epoch 57 Batch 10: Loss = 0.770969569683075\n",
      "Epoch 58 Batch 0: Loss = 0.3440016210079193\n",
      "Epoch 58 Batch 10: Loss = 0.14026089012622833\n",
      "Epoch 59 Batch 0: Loss = 0.20222638547420502\n",
      "Epoch 59 Batch 10: Loss = 0.2856665849685669\n",
      "Epoch 60 Batch 0: Loss = 0.09530077874660492\n",
      "Epoch 60 Batch 10: Loss = 0.12080347537994385\n",
      "Epoch 61 Batch 0: Loss = 0.3144828975200653\n",
      "Epoch 61 Batch 10: Loss = 0.24596039950847626\n",
      "Epoch 62 Batch 0: Loss = 0.0759483128786087\n",
      "Epoch 62 Batch 10: Loss = 0.09216205775737762\n",
      "Epoch 63 Batch 0: Loss = 0.03519686311483383\n",
      "Epoch 63 Batch 10: Loss = 0.06992726773023605\n",
      "Epoch 64 Batch 0: Loss = 0.12321402877569199\n",
      "Epoch 64 Batch 10: Loss = 0.05735758692026138\n",
      "Epoch 65 Batch 0: Loss = 0.03842391073703766\n",
      "Epoch 65 Batch 10: Loss = 0.020373690873384476\n",
      "Epoch 66 Batch 0: Loss = 0.12778526544570923\n",
      "Epoch 66 Batch 10: Loss = 0.0651170164346695\n",
      "Epoch 67 Batch 0: Loss = 0.07767446339130402\n",
      "Epoch 67 Batch 10: Loss = 0.059852518141269684\n",
      "Epoch 68 Batch 0: Loss = 0.03868144378066063\n",
      "Epoch 68 Batch 10: Loss = 0.016925934702157974\n",
      "Epoch 69 Batch 0: Loss = 0.008754954673349857\n",
      "Epoch 69 Batch 10: Loss = 0.022148385643959045\n",
      "Epoch 70 Batch 0: Loss = 0.005266200751066208\n",
      "Epoch 70 Batch 10: Loss = 0.016872212290763855\n",
      "Epoch 71 Batch 0: Loss = 0.007609316147863865\n",
      "Epoch 71 Batch 10: Loss = 0.011413748376071453\n",
      "Epoch 72 Batch 0: Loss = 0.030673300847411156\n",
      "Epoch 72 Batch 10: Loss = 0.006638593506067991\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73 Batch 0: Loss = 0.026760492473840714\n",
      "Epoch 73 Batch 10: Loss = 0.02108573354780674\n",
      "Epoch 74 Batch 0: Loss = 0.012625772505998611\n",
      "Epoch 74 Batch 10: Loss = 0.011247503571212292\n",
      "Epoch 75 Batch 0: Loss = 0.011805822141468525\n",
      "Epoch 75 Batch 10: Loss = 0.017143767327070236\n",
      "Epoch 76 Batch 0: Loss = 0.0031214184127748013\n",
      "Epoch 76 Batch 10: Loss = 0.014142121188342571\n",
      "Epoch 77 Batch 0: Loss = 0.08711720257997513\n",
      "Epoch 77 Batch 10: Loss = 0.05169191211462021\n",
      "Epoch 78 Batch 0: Loss = 0.02043822593986988\n",
      "Epoch 78 Batch 10: Loss = 0.02219279855489731\n",
      "Epoch 79 Batch 0: Loss = 0.01483422052115202\n",
      "Epoch 79 Batch 10: Loss = 0.3234531581401825\n",
      "Epoch 80 Batch 0: Loss = 0.10448519140481949\n",
      "Epoch 80 Batch 10: Loss = 0.10633489489555359\n",
      "Epoch 81 Batch 0: Loss = 0.06279421597719193\n",
      "Epoch 81 Batch 10: Loss = 0.07415515929460526\n",
      "Epoch 82 Batch 0: Loss = 0.20270031690597534\n",
      "Epoch 82 Batch 10: Loss = 0.12216739356517792\n",
      "Epoch 83 Batch 0: Loss = 0.2266218662261963\n",
      "Epoch 83 Batch 10: Loss = 0.39048337936401367\n",
      "Epoch 84 Batch 0: Loss = 0.2455286830663681\n",
      "Epoch 84 Batch 10: Loss = 0.577674150466919\n",
      "Epoch 85 Batch 0: Loss = 0.2579247057437897\n",
      "Epoch 85 Batch 10: Loss = 0.24994178116321564\n",
      "Epoch 86 Batch 0: Loss = 0.31120336055755615\n",
      "Epoch 86 Batch 10: Loss = 0.40375617146492004\n",
      "Epoch 87 Batch 0: Loss = 0.10116522759199142\n",
      "Epoch 87 Batch 10: Loss = 0.18390759825706482\n",
      "Epoch 88 Batch 0: Loss = 0.30117228627204895\n",
      "Epoch 88 Batch 10: Loss = 0.3009147644042969\n",
      "Epoch 89 Batch 0: Loss = 0.02351502701640129\n",
      "Epoch 89 Batch 10: Loss = 0.15514591336250305\n",
      "Epoch 90 Batch 0: Loss = 0.09996569156646729\n",
      "Epoch 90 Batch 10: Loss = 0.08745492249727249\n",
      "Epoch 91 Batch 0: Loss = 0.08477233350276947\n",
      "Epoch 91 Batch 10: Loss = 0.06161046773195267\n",
      "Epoch 92 Batch 0: Loss = 0.012190419249236584\n",
      "Epoch 92 Batch 10: Loss = 0.03154291585087776\n",
      "Epoch 93 Batch 0: Loss = 0.027210913598537445\n",
      "Epoch 93 Batch 10: Loss = 0.014544169418513775\n",
      "Epoch 94 Batch 0: Loss = 0.012274237349629402\n",
      "Epoch 94 Batch 10: Loss = 0.024343308061361313\n",
      "Epoch 95 Batch 0: Loss = 0.02093839831650257\n",
      "Epoch 95 Batch 10: Loss = 0.02223431132733822\n",
      "Epoch 96 Batch 0: Loss = 0.00695118447765708\n",
      "Epoch 96 Batch 10: Loss = 0.009614072740077972\n",
      "Epoch 97 Batch 0: Loss = 0.02635570615530014\n",
      "Epoch 97 Batch 10: Loss = 0.005583310965448618\n",
      "Epoch 98 Batch 0: Loss = 0.01564168557524681\n",
      "Epoch 98 Batch 10: Loss = 0.006548324599862099\n",
      "Epoch 99 Batch 0: Loss = 0.005917501635849476\n",
      "Epoch 99 Batch 10: Loss = 0.014653177000582218\n",
      "Test accuracy: 77.00%\n",
      "Epoch 0 Batch 0: Loss = 2.433896064758301\n",
      "Epoch 0 Batch 10: Loss = 2.1720328330993652\n",
      "Epoch 1 Batch 0: Loss = 1.9364080429077148\n",
      "Epoch 1 Batch 10: Loss = 1.9066998958587646\n",
      "Epoch 2 Batch 0: Loss = 1.6637141704559326\n",
      "Epoch 2 Batch 10: Loss = 1.5765421390533447\n",
      "Epoch 3 Batch 0: Loss = 1.550267219543457\n",
      "Epoch 3 Batch 10: Loss = 1.0883195400238037\n",
      "Epoch 4 Batch 0: Loss = 1.4449297189712524\n",
      "Epoch 4 Batch 10: Loss = 1.043243408203125\n",
      "Epoch 5 Batch 0: Loss = 1.6166361570358276\n",
      "Epoch 5 Batch 10: Loss = 1.2508057355880737\n",
      "Epoch 6 Batch 0: Loss = 1.4387798309326172\n",
      "Epoch 6 Batch 10: Loss = 1.5098421573638916\n",
      "Epoch 7 Batch 0: Loss = 0.770977258682251\n",
      "Epoch 7 Batch 10: Loss = 1.0810930728912354\n",
      "Epoch 8 Batch 0: Loss = 1.5066419839859009\n",
      "Epoch 8 Batch 10: Loss = 0.9145828485488892\n",
      "Epoch 9 Batch 0: Loss = 1.1182029247283936\n",
      "Epoch 9 Batch 10: Loss = 0.9316301941871643\n",
      "Epoch 10 Batch 0: Loss = 1.0873537063598633\n",
      "Epoch 10 Batch 10: Loss = 1.1109648942947388\n",
      "Epoch 11 Batch 0: Loss = 1.0849419832229614\n",
      "Epoch 11 Batch 10: Loss = 0.7246965169906616\n",
      "Epoch 12 Batch 0: Loss = 0.7969732284545898\n",
      "Epoch 12 Batch 10: Loss = 0.7467696666717529\n",
      "Epoch 13 Batch 0: Loss = 0.9738909602165222\n",
      "Epoch 13 Batch 10: Loss = 0.957080066204071\n",
      "Epoch 14 Batch 0: Loss = 0.9406967759132385\n",
      "Epoch 14 Batch 10: Loss = 0.5542561411857605\n",
      "Epoch 15 Batch 0: Loss = 0.8439412117004395\n",
      "Epoch 15 Batch 10: Loss = 0.6740183234214783\n",
      "Epoch 16 Batch 0: Loss = 0.5682006478309631\n",
      "Epoch 16 Batch 10: Loss = 0.8719597458839417\n",
      "Epoch 17 Batch 0: Loss = 0.6279255747795105\n",
      "Epoch 17 Batch 10: Loss = 0.6877488493919373\n",
      "Epoch 18 Batch 0: Loss = 0.4255000352859497\n",
      "Epoch 18 Batch 10: Loss = 0.6552300453186035\n",
      "Epoch 19 Batch 0: Loss = 0.7146245241165161\n",
      "Epoch 19 Batch 10: Loss = 0.7407881617546082\n",
      "Epoch 20 Batch 0: Loss = 0.7486598491668701\n",
      "Epoch 20 Batch 10: Loss = 0.5245748162269592\n",
      "Epoch 21 Batch 0: Loss = 0.4494592547416687\n",
      "Epoch 21 Batch 10: Loss = 0.763378918170929\n",
      "Epoch 22 Batch 0: Loss = 0.3692072331905365\n",
      "Epoch 22 Batch 10: Loss = 0.6577504277229309\n",
      "Epoch 23 Batch 0: Loss = 0.7086984515190125\n",
      "Epoch 23 Batch 10: Loss = 1.1851075887680054\n",
      "Epoch 24 Batch 0: Loss = 0.7671770453453064\n",
      "Epoch 24 Batch 10: Loss = 0.5326178669929504\n",
      "Epoch 25 Batch 0: Loss = 0.4402778148651123\n",
      "Epoch 25 Batch 10: Loss = 0.39504513144493103\n",
      "Epoch 26 Batch 0: Loss = 0.6950733661651611\n",
      "Epoch 26 Batch 10: Loss = 0.35386666655540466\n",
      "Epoch 27 Batch 0: Loss = 0.615318238735199\n",
      "Epoch 27 Batch 10: Loss = 0.27162718772888184\n",
      "Epoch 28 Batch 0: Loss = 0.5473911762237549\n",
      "Epoch 28 Batch 10: Loss = 0.8338879942893982\n",
      "Epoch 29 Batch 0: Loss = 0.4326842129230499\n",
      "Epoch 29 Batch 10: Loss = 0.3341040313243866\n",
      "Epoch 30 Batch 0: Loss = 0.5099375247955322\n",
      "Epoch 30 Batch 10: Loss = 0.52559494972229\n",
      "Epoch 31 Batch 0: Loss = 0.3015690743923187\n",
      "Epoch 31 Batch 10: Loss = 0.5322659015655518\n",
      "Epoch 32 Batch 0: Loss = 0.4864650368690491\n",
      "Epoch 32 Batch 10: Loss = 0.4199216961860657\n",
      "Epoch 33 Batch 0: Loss = 0.22684542834758759\n",
      "Epoch 33 Batch 10: Loss = 0.43742045760154724\n",
      "Epoch 34 Batch 0: Loss = 0.3391689360141754\n",
      "Epoch 34 Batch 10: Loss = 0.30645182728767395\n",
      "Epoch 35 Batch 0: Loss = 0.34859034419059753\n",
      "Epoch 35 Batch 10: Loss = 0.6603084802627563\n",
      "Epoch 36 Batch 0: Loss = 0.5177422761917114\n",
      "Epoch 36 Batch 10: Loss = 0.3321966826915741\n",
      "Epoch 37 Batch 0: Loss = 0.46598443388938904\n",
      "Epoch 37 Batch 10: Loss = 0.41275495290756226\n",
      "Epoch 38 Batch 0: Loss = 0.18949462473392487\n",
      "Epoch 38 Batch 10: Loss = 0.17156843841075897\n",
      "Epoch 39 Batch 0: Loss = 0.21925978362560272\n",
      "Epoch 39 Batch 10: Loss = 0.3613811135292053\n",
      "Epoch 40 Batch 0: Loss = 0.27827155590057373\n",
      "Epoch 40 Batch 10: Loss = 0.3054080605506897\n",
      "Epoch 41 Batch 0: Loss = 0.12194745987653732\n",
      "Epoch 41 Batch 10: Loss = 0.08275173604488373\n",
      "Epoch 42 Batch 0: Loss = 0.394804447889328\n",
      "Epoch 42 Batch 10: Loss = 0.2084628790616989\n",
      "Epoch 43 Batch 0: Loss = 0.08414427191019058\n",
      "Epoch 43 Batch 10: Loss = 0.10261844843626022\n",
      "Epoch 44 Batch 0: Loss = 0.3540252447128296\n",
      "Epoch 44 Batch 10: Loss = 0.1443897932767868\n",
      "Epoch 45 Batch 0: Loss = 0.3980841338634491\n",
      "Epoch 45 Batch 10: Loss = 0.14100392162799835\n",
      "Epoch 46 Batch 0: Loss = 0.1978830248117447\n",
      "Epoch 46 Batch 10: Loss = 0.1761316955089569\n",
      "Epoch 47 Batch 0: Loss = 0.0792461559176445\n",
      "Epoch 47 Batch 10: Loss = 0.07508032023906708\n",
      "Epoch 48 Batch 0: Loss = 0.1917642056941986\n",
      "Epoch 48 Batch 10: Loss = 0.23474444448947906\n",
      "Epoch 49 Batch 0: Loss = 0.10186288505792618\n",
      "Epoch 49 Batch 10: Loss = 0.23609988391399384\n",
      "Epoch 50 Batch 0: Loss = 0.3608105480670929\n",
      "Epoch 50 Batch 10: Loss = 0.21501320600509644\n",
      "Epoch 51 Batch 0: Loss = 0.23909877240657806\n",
      "Epoch 51 Batch 10: Loss = 0.198085755109787\n",
      "Epoch 52 Batch 0: Loss = 0.12325774133205414\n",
      "Epoch 52 Batch 10: Loss = 0.20678256452083588\n",
      "Epoch 53 Batch 0: Loss = 0.162180095911026\n",
      "Epoch 53 Batch 10: Loss = 0.05653471499681473\n",
      "Epoch 54 Batch 0: Loss = 0.19973528385162354\n",
      "Epoch 54 Batch 10: Loss = 0.05893978849053383\n",
      "Epoch 55 Batch 0: Loss = 0.08183525502681732\n",
      "Epoch 55 Batch 10: Loss = 0.09055815637111664\n",
      "Epoch 56 Batch 0: Loss = 0.15699364244937897\n",
      "Epoch 56 Batch 10: Loss = 0.11120965331792831\n",
      "Epoch 57 Batch 0: Loss = 0.04714912548661232\n",
      "Epoch 57 Batch 10: Loss = 0.10149036347866058\n",
      "Epoch 58 Batch 0: Loss = 0.026122327893972397\n",
      "Epoch 58 Batch 10: Loss = 0.11656835675239563\n",
      "Epoch 59 Batch 0: Loss = 0.10668230801820755\n",
      "Epoch 59 Batch 10: Loss = 0.0951932966709137\n",
      "Epoch 60 Batch 0: Loss = 0.30614349246025085\n",
      "Epoch 60 Batch 10: Loss = 0.1306578367948532\n",
      "Epoch 61 Batch 0: Loss = 0.11984720081090927\n",
      "Epoch 61 Batch 10: Loss = 0.1707678884267807\n",
      "Epoch 62 Batch 0: Loss = 0.10506770014762878\n",
      "Epoch 62 Batch 10: Loss = 0.11951080709695816\n",
      "Epoch 63 Batch 0: Loss = 0.2247944176197052\n",
      "Epoch 63 Batch 10: Loss = 0.08101770281791687\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64 Batch 0: Loss = 0.047366656363010406\n",
      "Epoch 64 Batch 10: Loss = 0.28797343373298645\n",
      "Epoch 65 Batch 0: Loss = 0.13192814588546753\n",
      "Epoch 65 Batch 10: Loss = 0.14113639295101166\n",
      "Epoch 66 Batch 0: Loss = 0.09916669130325317\n",
      "Epoch 66 Batch 10: Loss = 0.06429456174373627\n",
      "Epoch 67 Batch 0: Loss = 0.06994511187076569\n",
      "Epoch 67 Batch 10: Loss = 0.036414023488759995\n",
      "Epoch 68 Batch 0: Loss = 0.03177967295050621\n",
      "Epoch 68 Batch 10: Loss = 0.03588885813951492\n",
      "Epoch 69 Batch 0: Loss = 0.04464111849665642\n",
      "Epoch 69 Batch 10: Loss = 0.11529811471700668\n",
      "Epoch 70 Batch 0: Loss = 0.10322172939777374\n",
      "Epoch 70 Batch 10: Loss = 0.021638324484229088\n",
      "Epoch 71 Batch 0: Loss = 0.026202989742159843\n",
      "Epoch 71 Batch 10: Loss = 0.10359757393598557\n",
      "Epoch 72 Batch 0: Loss = 0.013467120006680489\n",
      "Epoch 72 Batch 10: Loss = 0.013534977100789547\n",
      "Epoch 73 Batch 0: Loss = 0.014670020900666714\n",
      "Epoch 73 Batch 10: Loss = 0.013568558730185032\n",
      "Epoch 74 Batch 0: Loss = 0.008852289989590645\n",
      "Epoch 74 Batch 10: Loss = 0.009156000800430775\n",
      "Epoch 75 Batch 0: Loss = 0.007369005586951971\n",
      "Epoch 75 Batch 10: Loss = 0.008584479801356792\n",
      "Epoch 76 Batch 0: Loss = 0.02418513409793377\n",
      "Epoch 76 Batch 10: Loss = 0.007803238928318024\n",
      "Epoch 77 Batch 0: Loss = 0.012075326405465603\n",
      "Epoch 77 Batch 10: Loss = 0.014761531725525856\n",
      "Epoch 78 Batch 0: Loss = 0.007024797145277262\n",
      "Epoch 78 Batch 10: Loss = 0.017095671966671944\n",
      "Epoch 79 Batch 0: Loss = 0.045174092054367065\n",
      "Epoch 79 Batch 10: Loss = 0.025213925167918205\n",
      "Epoch 80 Batch 0: Loss = 0.002784869633615017\n",
      "Epoch 80 Batch 10: Loss = 0.0104376757517457\n",
      "Epoch 81 Batch 0: Loss = 0.0046257684007287025\n",
      "Epoch 81 Batch 10: Loss = 0.0062322355806827545\n",
      "Epoch 82 Batch 0: Loss = 0.0050562238320708275\n",
      "Epoch 82 Batch 10: Loss = 0.0032941934186965227\n",
      "Epoch 83 Batch 0: Loss = 0.002827504649758339\n",
      "Epoch 83 Batch 10: Loss = 0.008433758281171322\n",
      "Epoch 84 Batch 0: Loss = 0.009599491953849792\n",
      "Epoch 84 Batch 10: Loss = 0.00961354561150074\n",
      "Epoch 85 Batch 0: Loss = 0.0035796104930341244\n",
      "Epoch 85 Batch 10: Loss = 0.0006208228878676891\n",
      "Epoch 86 Batch 0: Loss = 0.0066378191113471985\n",
      "Epoch 86 Batch 10: Loss = 0.0040865130722522736\n",
      "Epoch 87 Batch 0: Loss = 0.0018533110851421952\n",
      "Epoch 87 Batch 10: Loss = 0.014431551098823547\n",
      "Epoch 88 Batch 0: Loss = 0.004616087302565575\n",
      "Epoch 88 Batch 10: Loss = 0.0019686250016093254\n",
      "Epoch 89 Batch 0: Loss = 0.0031984630040824413\n",
      "Epoch 89 Batch 10: Loss = 0.016957884654402733\n",
      "Epoch 90 Batch 0: Loss = 0.010809400118887424\n",
      "Epoch 90 Batch 10: Loss = 0.0009354291250929236\n",
      "Epoch 91 Batch 0: Loss = 0.017882931977510452\n",
      "Epoch 91 Batch 10: Loss = 0.030375709757208824\n",
      "Epoch 92 Batch 0: Loss = 0.09649069607257843\n",
      "Epoch 92 Batch 10: Loss = 0.0037901659961789846\n",
      "Epoch 93 Batch 0: Loss = 0.015541810542345047\n",
      "Epoch 93 Batch 10: Loss = 0.0054176682606339455\n",
      "Epoch 94 Batch 0: Loss = 0.0039411885663867\n",
      "Epoch 94 Batch 10: Loss = 0.001904059899970889\n",
      "Epoch 95 Batch 0: Loss = 0.0028791124932467937\n",
      "Epoch 95 Batch 10: Loss = 0.006992350798100233\n",
      "Epoch 96 Batch 0: Loss = 0.001630404032766819\n",
      "Epoch 96 Batch 10: Loss = 0.0009867368498817086\n",
      "Epoch 97 Batch 0: Loss = 0.0013198015512898564\n",
      "Epoch 97 Batch 10: Loss = 0.005441649816930294\n",
      "Epoch 98 Batch 0: Loss = 0.001407564035616815\n",
      "Epoch 98 Batch 10: Loss = 0.0006382659776136279\n",
      "Epoch 99 Batch 0: Loss = 0.0014498779783025384\n",
      "Epoch 99 Batch 10: Loss = 0.0010788608342409134\n",
      "Test accuracy: 71.00%\n",
      "Epoch 0 Batch 0: Loss = 2.547285318374634\n",
      "Epoch 0 Batch 10: Loss = 2.2347187995910645\n",
      "Epoch 1 Batch 0: Loss = 2.0145621299743652\n",
      "Epoch 1 Batch 10: Loss = 1.5791797637939453\n",
      "Epoch 2 Batch 0: Loss = 1.6666147708892822\n",
      "Epoch 2 Batch 10: Loss = 1.7756298780441284\n",
      "Epoch 3 Batch 0: Loss = 1.496700644493103\n",
      "Epoch 3 Batch 10: Loss = 1.3458530902862549\n",
      "Epoch 4 Batch 0: Loss = 1.294716715812683\n",
      "Epoch 4 Batch 10: Loss = 1.1836473941802979\n",
      "Epoch 5 Batch 0: Loss = 1.285130262374878\n",
      "Epoch 5 Batch 10: Loss = 1.2463810443878174\n",
      "Epoch 6 Batch 0: Loss = 0.9398206472396851\n",
      "Epoch 6 Batch 10: Loss = 1.307390809059143\n",
      "Epoch 7 Batch 0: Loss = 1.1473865509033203\n",
      "Epoch 7 Batch 10: Loss = 1.381096601486206\n",
      "Epoch 8 Batch 0: Loss = 0.8926757574081421\n",
      "Epoch 8 Batch 10: Loss = 1.1865476369857788\n",
      "Epoch 9 Batch 0: Loss = 1.083392858505249\n",
      "Epoch 9 Batch 10: Loss = 0.7011755108833313\n",
      "Epoch 10 Batch 0: Loss = 0.9571007490158081\n",
      "Epoch 10 Batch 10: Loss = 0.8929515480995178\n",
      "Epoch 11 Batch 0: Loss = 0.9365448951721191\n",
      "Epoch 11 Batch 10: Loss = 0.9856565594673157\n",
      "Epoch 12 Batch 0: Loss = 0.7974151372909546\n",
      "Epoch 12 Batch 10: Loss = 0.7652793526649475\n",
      "Epoch 13 Batch 0: Loss = 0.8133466839790344\n",
      "Epoch 13 Batch 10: Loss = 0.93172687292099\n",
      "Epoch 14 Batch 0: Loss = 0.5629516839981079\n",
      "Epoch 14 Batch 10: Loss = 0.8414017558097839\n",
      "Epoch 15 Batch 0: Loss = 0.8881121277809143\n",
      "Epoch 15 Batch 10: Loss = 0.6269156336784363\n",
      "Epoch 16 Batch 0: Loss = 0.9008498787879944\n",
      "Epoch 16 Batch 10: Loss = 0.5682854652404785\n",
      "Epoch 17 Batch 0: Loss = 0.7193712592124939\n"
     ]
    }
   ],
   "source": [
    "for i, fold in enumerate(dataset_splits):\n",
    "    # 将4个子集合并成一个训练集\n",
    "    train_dataset = torch.utils.data.ConcatDataset([dataset_splits[j] for j in range(5) if j != i])\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "    test_loader = DataLoader(fold, batch_size=32, shuffle=False)\n",
    "    n_epochs = 100\n",
    "    model = MusicCNN(n_classes)\n",
    "    model.to(device)\n",
    "    optimizer = optim.Adam(model.parameters())\n",
    "    for epoch in range(n_epochs):\n",
    "        for batch, (magnitude, label) in enumerate(train_loader):\n",
    "            # print(\"label\",label)\n",
    "            # print(i)\n",
    "            optimizer.zero_grad()\n",
    "            # magnitude = torch.stack(magnitude)\n",
    "            # magnitude = magnitude.permute(1, 0, 2, 3)\n",
    "            # print(magnitude.shape)\n",
    "            # size = np.array(magnitude[0]).shape\n",
    "            # print(\"magshape\",magnitude.shape)\n",
    "            # new_label = batch_change(magnitude,label)\n",
    "            # print(device)\n",
    "            magnitude = magnitude.type(torch.cuda.FloatTensor)\n",
    "            magnitude.to(device)\n",
    "            label = label.type(torch.cuda.LongTensor)\n",
    "            label.to(device)\n",
    "            output = model(magnitude)\n",
    "            loss = loss_function(output, label.squeeze())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if batch % 10 == 0:\n",
    "                print(\"Epoch {} Batch {}: Loss = {}\".format(epoch, batch, loss.item()))\n",
    "    torch.save(model.state_dict(), 'model_new'+str(i)+'.pt')\n",
    "    accuracy = evaluate(model, test_loader)\n",
    "    print(f\"Test accuracy: {accuracy:.2f}%\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "、## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "n_epochs = 100\n",
    "for epoch in range(n_epochs):\n",
    "    for i, (magnitude, label) in enumerate(dataloader):\n",
    "        # print(\"label\",label)\n",
    "        # print(i)\n",
    "        optimizer.zero_grad()\n",
    "        # magnitude = torch.stack(magnitude)\n",
    "        # magnitude = magnitude.permute(1, 0, 2, 3)\n",
    "        # print(magnitude.shape)\n",
    "        # size = np.array(magnitude[0]).shape\n",
    "        # print(\"magshape\",magnitude.shape)\n",
    "        # new_label = batch_change(magnitude,label)\n",
    "        # print(device)\n",
    "        magnitude = magnitude.type(torch.cuda.FloatTensor)\n",
    "        magnitude.to(device)\n",
    "        label = label.type(torch.cuda.LongTensor)\n",
    "        label.to(device)\n",
    "        output = model(magnitude)\n",
    "        loss = loss_function(output, label.squeeze())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if i % 10 == 0:\n",
    "            print(\"Epoch {} Batch {}: Loss = {}\".format(epoch, i, loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'model_new.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "test_loader = DataLoader(test_set, batch_size=32, shuffle=True)\n",
    "\n",
    "accuracy = evaluate(model, test_loader)\n",
    "print(f\"Test accuracy: {accuracy:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "music_genre",
   "language": "python",
   "name": "music_genre"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "64c860a3d298e014a86325ad7e804793bd14928987cd6054e77cd22c5ed369ab"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
